{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afb73341-d198-4d90-bf99-7f131edc071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "# STEP 1 - IMPORT PACKAGES AND METADATA\n",
    "##########\n",
    "\n",
    "# import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import fred_msa\n",
    "import regex as re\n",
    "\n",
    "# import datasets\n",
    "\n",
    "data_path = '..\\\\raw-data'\n",
    "\n",
    "# city-county crosswalk\n",
    "crosswalk = pd.read_csv(os.path.join(data_path, 'msa-county-crosswalk.csv'), encoding='cp1252', \n",
    "                        usecols=['code', 'county', 'msa'])\n",
    "\n",
    "# remove nulls\n",
    "crosswalk = crosswalk[crosswalk.msa.notna()]\n",
    "crosswalk['city'] = crosswalk.msa.apply(fred_msa.split_city)\n",
    "crosswalk['state'] = crosswalk.msa.apply(fred_msa.extract_state)\n",
    "\n",
    "# msas used in analysis\n",
    "msas_to_use = pd.read_csv(os.path.join(data_path, 'msas-to-use.csv'))\n",
    "\n",
    "# state abbreviations\n",
    "states = pd.read_csv(os.path.join(data_path, 'states.csv'))\n",
    "\n",
    "# get list of relevant counties (counties in relevant msas)\n",
    "\n",
    "counties_to_use = pd.merge(msas_to_use, crosswalk, how='left', on=['city', 'state'], validate='one_to_many')\n",
    "\n",
    "counties_to_use = counties_to_use.rename(columns={'city' : 'msa_city', 'state' : 'msa_state'})\n",
    "\n",
    "##########\n",
    "# STEP 2 - SET UP PARAMETERS FOR API\n",
    "##########\n",
    "\n",
    "# extract state IDs for FRED API\n",
    "\n",
    "api_key = 'a37b50cd27afbc3ce23a81ddc5541dec'\n",
    "endpoint = 'https://api.stlouisfed.org/fred/series/categories'\n",
    "\n",
    "state_ids = fred_msa.get_state_ids(api_key)\n",
    "\n",
    "##########\n",
    "# STEP 3 - GET ALL MSA AND COUNTY IDS\n",
    "##########\n",
    "\n",
    "msa_ids = pd.DataFrame() # empty df for msa data\n",
    "county_ids = pd.DataFrame() # empty df for county data\n",
    "\n",
    "for state, state_id in state_ids.items(): # loop through states\n",
    "    state_msa_dict = fred_msa.get_msa_cats(api_key, state_id) # get state msa data from API\n",
    "    \n",
    "    if len(state_msa_dict) > 0: # some states have no MSAs\n",
    "        \n",
    "        states_msa = pd.Series(state_msa_dict.keys()).apply(fred_msa.extract_state) # extract state name from msa\n",
    "        state_msa_df = pd.DataFrame({'city' : pd.Series(list(state_msa_dict.keys())).apply(fred_msa.split_city),\n",
    "                                     'state' : states_msa, 'ID' : list(state_msa_dict.values())}) # create df with metadata for state's msas\n",
    "        msa_ids = msa_ids.append(state_msa_df) # append to larger df with msa info for all states\n",
    "    \n",
    "    time.sleep(3) # ensure process not shut out for too many API calls\n",
    "    \n",
    "    state_county_dict = fred_msa.get_county_cats(api_key, state_id) # get state county data from API\n",
    "    states_county = pd.Series(state_county_dict.keys()).apply(fred_msa.extract_state) # extract state name \n",
    "    \n",
    "    # df with state county info\n",
    "    state_county_df = pd.DataFrame({'county' : list(state_county_dict.keys()),\n",
    "                                    'state' : states_county, 'ID' : list(state_county_dict.values())})\n",
    "    \n",
    "    county_ids = county_ids.append(state_county_df) # append to larger df with county info for all states\n",
    "    \n",
    "    time.sleep(3) # ensure process not shut out for too many API calls\n",
    "\n",
    "##########\n",
    "# STEP 4 - CLEAN UP DATFRAMES AND MERGE\n",
    "##########\n",
    "\n",
    "# some msas span multiple states and will therefore be duplicated\n",
    "msa_ids = msa_ids.drop_duplicates(subset=['city', 'state'])\n",
    "\n",
    "# dictionaries for state abbreviations (needed b/c states written out in county crosswalk but\n",
    "# abbreviated in msa and county id dfs)\n",
    "\n",
    "state_to_ab = {states.loc[idx, 'State'] : states.loc[idx, 'Code'] for idx in range(len(states))}\n",
    "ab_to_state = {states.loc[idx, 'Code'] : states.loc[idx, 'State'] for idx in range(len(states))}\n",
    "\n",
    "# convert to abbreviation in counties df\n",
    "counties_to_use['county_state'] = counties_to_use.county.apply(fred_msa.extract_state).map(state_to_ab)\n",
    "\n",
    "# remove state from county name\n",
    "county_ids.county = [re.split(',', c)[0] for c in county_ids.county]\n",
    "counties_to_use.county = [re.split(',', c)[0] for c in counties_to_use.county]\n",
    "\n",
    "# merge county crosswalk with county ids (get county ids for relevant counties only)\n",
    "counties_to_use = pd.merge(counties_to_use, county_ids, how='left', left_on=['county', 'county_state'],\n",
    "         right_on=['county', 'state'], validate='one_to_one')\n",
    "\n",
    "# get msa ids and metadata for only relevant msas\n",
    "msas_to_use = pd.merge(msas_to_use, msa_ids,\n",
    "         how='left', on=['city', 'state'], validate='one_to_one')\n",
    "\n",
    "##########\n",
    "# STEP 5 - GET LIST OF AVAILABLE SERIES FOR EACH MSA\n",
    "##########\n",
    "\n",
    "all_msa_series = pd.DataFrame()\n",
    "\n",
    "for idx in range(len(msas_to_use)):\n",
    "    msa_series = fred_msa.get_loc_series_list(msas_to_use.ID[idx], api_key)\n",
    "    msa_series['city'] = msas_to_use.city[idx]\n",
    "    msa_series['state'] = msas_to_use.state[idx]\n",
    "    \n",
    "    all_msa_series = all_msa_series.append(msa_series).reset_index(drop=True)\n",
    "    time.sleep(3)\n",
    "\n",
    "all_msa_series.to_csv('..\\\\metadata\\msa-series.csv', index=False)\n",
    "\n",
    "##########\n",
    "# STEP 6 - GET LIST OF AVAILABLE SERIES FOR EACH COUNTY\n",
    "##########\n",
    "\n",
    "all_county_series = pd.DataFrame()\n",
    "\n",
    "for idx in range(len(counties_to_use)):\n",
    "    county_series = fred_msa.get_loc_series_list(counties_to_use.ID[idx], api_key)\n",
    "    county_series['county'] = counties_to_use.county[idx]\n",
    "    county_series['state'] = counties_to_use.state[idx]\n",
    "    county_series['city'] = counties_to_use.msa_city[idx]\n",
    "    county_series['msa_state'] = counties_to_use.msa_state[idx]\n",
    "    \n",
    "    all_county_series = all_county_series.append(county_series).reset_index(drop=True)\n",
    "    time.sleep(3)\n",
    "\n",
    "all_county_series.to_csv('..\\\\metadata\\county-series.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c00f8ff-3851-41da-91d6-3f55d0e60021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alabama': 27282,\n",
       " 'Alaska': 27283,\n",
       " 'Arizona': 27284,\n",
       " 'Arkansas': 149,\n",
       " 'California': 27286,\n",
       " 'Colorado': 27287,\n",
       " 'Connecticut': 27288,\n",
       " 'Delaware': 27289,\n",
       " 'District of Columbia': 27290,\n",
       " 'Florida': 27291,\n",
       " 'Georgia': 27292,\n",
       " 'Hawaii': 27293,\n",
       " 'Idaho': 27294,\n",
       " 'Illinois': 150,\n",
       " 'Indiana': 151,\n",
       " 'Iowa': 27297,\n",
       " 'Kansas': 27298,\n",
       " 'Kentucky': 152,\n",
       " 'Louisiana': 27300,\n",
       " 'Maine': 27301,\n",
       " 'Maryland': 27302,\n",
       " 'Massachusetts': 27303,\n",
       " 'Michigan': 27304,\n",
       " 'Minnesota': 27305,\n",
       " 'Mississippi': 153,\n",
       " 'Missouri': 154,\n",
       " 'Montana': 27308,\n",
       " 'Nebraska': 27309,\n",
       " 'Nevada': 27310,\n",
       " 'New Hampshire': 27311,\n",
       " 'New Jersey': 27312,\n",
       " 'New Mexico': 27313,\n",
       " 'New York': 27314,\n",
       " 'North Carolina': 27315,\n",
       " 'North Dakota': 27316,\n",
       " 'Ohio': 27317,\n",
       " 'Oklahoma': 27318,\n",
       " 'Oregon': 27319,\n",
       " 'Pennsylvania': 27320,\n",
       " 'Rhode Island': 27322,\n",
       " 'South Carolina': 27323,\n",
       " 'South Dakota': 27324,\n",
       " 'Tennessee': 193,\n",
       " 'Texas': 27326,\n",
       " 'Utah': 27328,\n",
       " 'Vermont': 27329,\n",
       " 'Virginia': 27330,\n",
       " 'West Virginia': 27332,\n",
       " 'Washington': 27331,\n",
       " 'Wisconsin': 27333,\n",
       " 'Wyoming': 27334}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k : v for k, v in state_ids.items() if k in list(states.State)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ecc50fb-bf9f-41d7-af4a-6aee4aaf0ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(states.State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41b83d3-9a69-4444-95ca-751f6bc8dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# STEP 1 - IMPORT PACKAGES AND METADATA\n",
    "##########\n",
    "\n",
    "# import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import fred_msa\n",
    "import regex as re\n",
    "\n",
    "# import datasets\n",
    "\n",
    "data_path = '..\\\\raw-data'\n",
    "\n",
    "# city-county crosswalk\n",
    "crosswalk = pd.read_csv(os.path.join(data_path, 'msa-county-crosswalk.csv'), encoding='cp1252', \n",
    "                        usecols=['code', 'county', 'msa'])\n",
    "\n",
    "# remove nulls\n",
    "crosswalk = crosswalk[crosswalk.msa.notna()]\n",
    "crosswalk['city'] = crosswalk.msa.apply(fred_msa.split_city)\n",
    "crosswalk['state'] = crosswalk.msa.apply(fred_msa.extract_state)\n",
    "\n",
    "# msas used in analysis\n",
    "msas_to_use = pd.read_csv(os.path.join(data_path, 'msas-to-use.csv'))\n",
    "\n",
    "# state abbreviations\n",
    "states = pd.read_csv(os.path.join(data_path, 'states.csv'))\n",
    "\n",
    "# dictionaries for state abbreviations (needed b/c states written out in county crosswalk but\n",
    "# abbreviated in msa and county id dfs)\n",
    "state_to_ab = {states.loc[idx, 'State'] : states.loc[idx, 'Code'] for idx in range(len(states))}\n",
    "ab_to_state = {states.loc[idx, 'Code'] : states.loc[idx, 'State'] for idx in range(len(states))}\n",
    "\n",
    "# get list of relevant counties (counties in relevant msas)\n",
    "\n",
    "counties_to_use = pd.merge(msas_to_use, crosswalk, how='left', on=['city', 'state'], validate='one_to_many')\n",
    "\n",
    "counties_to_use = counties_to_use.rename(columns={'city' : 'msa_city', 'state' : 'msa_state'})\n",
    "\n",
    "##########\n",
    "# STEP 2 - SET UP PARAMETERS FOR API\n",
    "##########\n",
    "\n",
    "# extract state IDs for FRED API\n",
    "\n",
    "api_key = 'a37b50cd27afbc3ce23a81ddc5541dec'\n",
    "endpoint = 'https://api.stlouisfed.org/fred/series/categories'\n",
    "\n",
    "state_ids = fred_msa.get_state_ids(api_key)\n",
    "\n",
    "state_ids = {k : v for k, v in state_ids.items() if k in list(states.State)} # filter for proper states (e.g. not Puerto Rico)\n",
    "\n",
    "##########\n",
    "# STEP 3 - GET ALL MSA AND COUNTY IDS\n",
    "##########\n",
    "\n",
    "msa_ids = pd.DataFrame() # empty df for msa data\n",
    "county_ids = pd.DataFrame() # empty df for county data\n",
    "\n",
    "for state, state_id in state_ids.items(): # loop through states\n",
    "    state_msa_dict = fred_msa.get_msa_cats(api_key, state_id) # get state msa data from API\n",
    "    \n",
    "    state_msa_dict = {k : v for k, v in state_msa_dict.items() if '(CMSA)' not in k}\n",
    "    \n",
    "    if len(state_msa_dict) > 0: # some states have no MSAs\n",
    "        \n",
    "        states_msa = pd.Series(state_msa_dict.keys()).apply(fred_msa.extract_state) # extract state name from msa\n",
    "        \n",
    "        # create df with metadata for state's msas\n",
    "        state_msa_df = pd.DataFrame({'city' : pd.Series(list(state_msa_dict.keys())).apply(fred_msa.split_city),\n",
    "                                     'msa_state' : states_msa, 'ID' : list(state_msa_dict.values())})\n",
    "        \n",
    "        state_msa_df['state'] = state_to_ab[state]\n",
    "        \n",
    "        msa_ids = msa_ids.append(state_msa_df) # append to larger df with msa info for all states\n",
    "    \n",
    "    time.sleep(3) # ensure process not shut out for too many API calls\n",
    "    \n",
    "    state_county_dict = fred_msa.get_county_cats(api_key, state_id) # get state county data from API\n",
    "    states_county = pd.Series(state_county_dict.keys()).apply(fred_msa.extract_state) # extract state name \n",
    "    \n",
    "    # df with state county info\n",
    "    state_county_df = pd.DataFrame({'county' : list(state_county_dict.keys()),\n",
    "                                    'state' : states_county, 'ID' : list(state_county_dict.values())})\n",
    "    \n",
    "    county_ids = county_ids.append(state_county_df) # append to larger df with county info for all states\n",
    "    \n",
    "    time.sleep(3) # ensure process not shut out for too many API calls\n",
    "\n",
    "\n",
    "##########\n",
    "# STEP 4 - CLEAN UP DATFRAMES AND MERGE\n",
    "##########\n",
    "\n",
    "# some msas may have duplicates\n",
    "msa_ids = msa_ids.drop_duplicates(subset=['city', 'state', 'msa_state'])\n",
    "\n",
    "# most msas span multiple states and will therefore be duplicated - match to home state\n",
    "msa_ids = msa_ids[msa_ids.msa_state == msa_ids.state]\n",
    "\n",
    "# convert to abbreviation in counties df\n",
    "counties_to_use['county_state'] = counties_to_use.county.apply(fred_msa.extract_state).map(state_to_ab)\n",
    "\n",
    "# remove state from county name\n",
    "county_ids.county = [re.split(',', c)[0] for c in county_ids.county]\n",
    "counties_to_use.county = [re.split(',', c)[0] for c in counties_to_use.county]\n",
    "\n",
    "# merge county crosswalk with county ids (get county ids for relevant counties only)\n",
    "counties_to_use = pd.merge(counties_to_use, county_ids, how='left', left_on=['county', 'county_state'],\n",
    "         right_on=['county', 'state'], validate='one_to_one')\n",
    "\n",
    "# get msa ids and metadata for only relevant msas\n",
    "msas_to_use = pd.merge(msas_to_use, msa_ids,\n",
    "         how='left', on=['city', 'state'], validate='one_to_one')\n",
    "\n",
    "##########\n",
    "# STEP 5 - GET LIST OF AVAILABLE SERIES FOR EACH MSA\n",
    "##########\n",
    "\n",
    "all_msa_series = pd.DataFrame()\n",
    "\n",
    "for idx in range(len(msas_to_use)):\n",
    "    msa_series = fred_msa.get_loc_series_list(msas_to_use.ID[idx], api_key)\n",
    "    msa_series['city'] = msas_to_use.city[idx]\n",
    "    msa_series['msa_state'] = msas_to_use.state[idx]\n",
    "    \n",
    "    all_msa_series = all_msa_series.append(msa_series).reset_index(drop=True)\n",
    "    time.sleep(3)\n",
    "\n",
    "all_msa_series.to_csv('..\\\\metadata\\msa-series.csv', index=False)\n",
    "\n",
    "##########\n",
    "# STEP 6 - GET LIST OF AVAILABLE SERIES FOR EACH COUNTY\n",
    "##########\n",
    "\n",
    "all_county_series = pd.DataFrame()\n",
    "\n",
    "for idx in range(len(counties_to_use)):\n",
    "    county_series = fred_msa.get_loc_series_list(counties_to_use.ID[idx], api_key)\n",
    "    county_series['county'] = counties_to_use.county[idx]\n",
    "    county_series['state'] = counties_to_use.state[idx]\n",
    "    county_series['city'] = counties_to_use.msa_city[idx]\n",
    "    county_series['msa_state'] = counties_to_use.msa_state[idx]\n",
    "    \n",
    "    all_county_series = all_county_series.append(county_series).reset_index(drop=True)\n",
    "    time.sleep(3)\n",
    "\n",
    "all_county_series.to_csv('..\\\\metadata\\county-series.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
